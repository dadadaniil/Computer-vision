{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Лабораторная работа №2: Выделение признаков изображений\n",
        "\n",
        "## Цель работы\n",
        "Изучение методов выделения признаков на изображениях: обнаружение линий и окружностей с помощью преобразования Хафа, а также сегментация изображений на основе текстурных признаков.\n",
        "\n",
        "## Выполненные задачи\n",
        "\n",
        "### a. Выделение прямых и окружностей\n",
        "1. Обнаружение прямых линий с использованием преобразования Хафа (HoughLinesP)\n",
        "2. Обнаружение окружностей с использованием преобразования Хафа (HoughCircles)\n",
        "\n",
        "### c. Сегментация по текстуре\n",
        "1. Реализация алгоритма роста регионов (Region Growing)\n",
        "2. Использование локальных бинарных паттернов (LBP) для анализа текстуры\n",
        "3. Комбинированный подход: анализ цвета и текстуры для точной сегментации\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Импорт необходимых библиотек\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import local_binary_pattern\n",
        "from collections import deque\n",
        "import os\n",
        "\n",
        "# Настройка отображения\n",
        "plt.rcParams['figure.figsize'] = (15, 10)\n",
        "plt.rcParams['font.size'] = 10\n",
        "print(\"✓ Библиотеки успешно импортированы\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Функции обработки изображений\n",
        "\n",
        "Ниже представлены все функции для выделения признаков, с подробными комментариями.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_hough_lines(image):\n",
        "    \"\"\"\n",
        "    Обнаружение прямых линий на изображении с использованием преобразования Хафа.\n",
        "    \n",
        "    Алгоритм:\n",
        "    1. Преобразование изображения в оттенки серого (если необходимо)\n",
        "    2. Применение детектора краёв Canny\n",
        "    3. Применение вероятностного преобразования Хафа (HoughLinesP)\n",
        "    4. Отрисовка найденных линий на исходном изображении\n",
        "    \n",
        "    Параметры:\n",
        "        image: входное изображение (BGR или серое)\n",
        "    \n",
        "    Возвращает:\n",
        "        output_image: изображение с отмеченными линиями (зелёный цвет)\n",
        "    \"\"\"\n",
        "    # Преобразуем в серое, если изображение цветное\n",
        "    if len(image.shape) == 3:\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray_image = image.copy()\n",
        "    \n",
        "    # Применяем детектор краёв Canny\n",
        "    # Параметры: нижний порог = 50, верхний порог = 150\n",
        "    edges = cv2.Canny(gray_image, 50, 150, apertureSize=3)\n",
        "    \n",
        "    # Применяем вероятностное преобразование Хафа\n",
        "    # Параметры:\n",
        "    # - rho = 1: разрешение по расстоянию в пикселях\n",
        "    # - theta = pi/180: разрешение по углу в радианах (1 градус)\n",
        "    # - threshold = 100: минимальное количество пересечений для обнаружения линии\n",
        "    # - minLineLength = 100: минимальная длина линии\n",
        "    # - maxLineGap = 10: максимальный разрыв между сегментами линии\n",
        "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 100, minLineLength=100, maxLineGap=10)\n",
        "    \n",
        "    # Создаём копию исходного изображения для отрисовки\n",
        "    output_image = image.copy()\n",
        "    \n",
        "    # Отрисовываем найденные линии\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            cv2.line(output_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        print(f\"Найдено линий: {len(lines)}\")\n",
        "    else:\n",
        "        print(\"Линии не найдены\")\n",
        "    \n",
        "    return output_image\n",
        "\n",
        "\n",
        "def find_hough_circles(image):\n",
        "    \"\"\"\n",
        "    Обнаружение окружностей на изображении с использованием преобразования Хафа.\n",
        "    \n",
        "    Алгоритм:\n",
        "    1. Преобразование изображения в оттенки серого\n",
        "    2. Предобработка: размытие по Гауссу для снижения шума\n",
        "    3. Адаптивная эквализация гистограммы (CLAHE) для улучшения контраста\n",
        "    4. Применение преобразования Хафа для окружностей\n",
        "    5. Отрисовка найденных окружностей и их центров\n",
        "    \n",
        "    Параметры:\n",
        "        image: входное изображение (BGR или серое)\n",
        "    \n",
        "    Возвращает:\n",
        "        output_image: изображение с отмеченными окружностями (зелёный) и центрами (красный)\n",
        "    \"\"\"\n",
        "    # Преобразуем в серое, если изображение цветное\n",
        "    if len(image.shape) == 3:\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray_image = image.copy()\n",
        "    \n",
        "    # Предобработка: размытие для снижения шума\n",
        "    img_blur = cv2.GaussianBlur(gray_image, (9, 9), 2)\n",
        "    \n",
        "    # Адаптивная эквализация гистограммы для улучшения контраста\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    img_enhanced = clahe.apply(img_blur)\n",
        "    \n",
        "    # Применяем преобразование Хафа для окружностей\n",
        "    # Параметры:\n",
        "    # - method = HOUGH_GRADIENT: метод обнаружения\n",
        "    # - dp = 1: соотношение разрешения аккумулятора к разрешению изображения\n",
        "    # - minDist = 30: минимальное расстояние между центрами окружностей\n",
        "    # - param1 = 100: верхний порог для детектора Canny\n",
        "    # - param2 = 30: порог для центра окружности (чем меньше, тем больше ложных срабатываний)\n",
        "    # - minRadius = 5: минимальный радиус окружности\n",
        "    # - maxRadius = 300: максимальный радиус окружности\n",
        "    circles = cv2.HoughCircles(img_enhanced, cv2.HOUGH_GRADIENT, \n",
        "                               dp=1, \n",
        "                               minDist=30,\n",
        "                               param1=100,\n",
        "                               param2=30,\n",
        "                               minRadius=5, \n",
        "                               maxRadius=300)\n",
        "    \n",
        "    # Создаём копию исходного изображения для отрисовки\n",
        "    output_image = image.copy()\n",
        "    \n",
        "    # Отрисовываем найденные окружности\n",
        "    if circles is not None:\n",
        "        circles = np.uint16(np.around(circles))\n",
        "        for i in circles[0, :]:\n",
        "            # Рисуем окружность (зелёным)\n",
        "            cv2.circle(output_image, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
        "            # Рисуем центр (красным)\n",
        "            cv2.circle(output_image, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
        "        print(f\"Найдено окружностей: {len(circles[0])}\")\n",
        "    else:\n",
        "        print(\"Окружности не найдены\")\n",
        "    \n",
        "    return output_image\n",
        "\n",
        "\n",
        "def segment_by_texture(image, seed_x, seed_y):\n",
        "    \"\"\"\n",
        "    Сегментация изображения по текстуре с использованием алгоритма роста регионов.\n",
        "    \n",
        "    Алгоритм:\n",
        "    1. Преобразование изображения в оттенки серого\n",
        "    2. Уменьшение разрешения для ускорения обработки (опционально)\n",
        "    3. Вычисление локальных бинарных паттернов (LBP) для всего изображения\n",
        "    4. Извлечение целевого патча вокруг затравочной точки\n",
        "    5. Вычисление гистограммы LBP для целевого патча\n",
        "    6. Алгоритм роста регионов:\n",
        "       - Быстрая проверка по цветовому сходству\n",
        "       - Медленная проверка по текстурному сходству (только для похожих по цвету)\n",
        "    7. Масштабирование маски обратно к исходному размеру\n",
        "    8. Морфологическая обработка для сглаживания результата\n",
        "    9. Наложение результата на исходное изображение\n",
        "    \n",
        "    Параметры:\n",
        "        image: входное BGR изображение\n",
        "        seed_x: X координата затравочной точки\n",
        "        seed_y: Y координата затравочной точки\n",
        "    \n",
        "    Возвращает:\n",
        "        output_image: изображение с выделенным регионом (зелёным цветом)\n",
        "        success: булево значение, True если сегментация успешна\n",
        "    \"\"\"\n",
        "    # Преобразуем в серое\n",
        "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    h, w = grayscale_image.shape\n",
        "    \n",
        "    # Уменьшаем разрешение для ускорения (если изображение большое)\n",
        "    scale_factor = 2 if max(h, w) > 800 else 1\n",
        "    small_gray = cv2.resize(grayscale_image, (w // scale_factor, h // scale_factor))\n",
        "    small_color = cv2.resize(image, (w // scale_factor, h // scale_factor))\n",
        "    \n",
        "    # Пересчитываем координаты seed\n",
        "    sx, sy = seed_x // scale_factor, seed_y // scale_factor\n",
        "    sh, sw = small_gray.shape\n",
        "    \n",
        "    # Вычисляем LBP (Local Binary Patterns) для всего изображения\n",
        "    # LBP - это метод описания текстуры, который кодирует локальную структуру\n",
        "    radius = 1\n",
        "    n_points = 8 * radius  # Количество соседних точек\n",
        "    lbp = local_binary_pattern(small_gray, n_points, radius, 'uniform')\n",
        "    \n",
        "    # Размер патча для анализа текстуры\n",
        "    patch_size = 9\n",
        "    half_patch = patch_size // 2\n",
        "    \n",
        "    # Проверяем, что seed point не слишком близко к краю\n",
        "    if not (half_patch <= sx < sw - half_patch and half_patch <= sy < sh - half_patch):\n",
        "        print(\"Ошибка: точка слишком близко к краю изображения\")\n",
        "        return image.copy(), False\n",
        "    \n",
        "    # Извлекаем целевой патч вокруг затравочной точки\n",
        "    seed_patch_lbp = lbp[sy - half_patch: sy + half_patch + 1,\n",
        "                         sx - half_patch: sx + half_patch + 1]\n",
        "    \n",
        "    # Вычисляем гистограмму LBP для целевого патча\n",
        "    target_lbp_hist, _ = np.histogram(seed_patch_lbp, bins=n_points + 2, \n",
        "                                      range=(0, n_points + 2), density=True)\n",
        "    \n",
        "    # Извлекаем цвет затравочной точки для быстрой фильтрации\n",
        "    seed_color = small_color[sy, sx].astype(np.float32)\n",
        "    \n",
        "    # Инициализируем маску и очередь для алгоритма роста регионов\n",
        "    mask = np.zeros((sh, sw), dtype=np.uint8)\n",
        "    queue = deque([(sx, sy)])\n",
        "    mask[sy, sx] = 255\n",
        "    \n",
        "    # Пороговые значения для сходства\n",
        "    color_threshold = 40  # Максимальная разница по цвету (евклидово расстояние)\n",
        "    texture_threshold = 0.5  # Минимальная корреляция текстуры (от -1 до 1)\n",
        "    \n",
        "    # Алгоритм роста регионов\n",
        "    processed_pixels = 0\n",
        "    while queue:\n",
        "        x, y = queue.popleft()\n",
        "        \n",
        "        # Проверяем 4-связных соседей (вверх, вниз, влево, вправо)\n",
        "        for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n",
        "            nx, ny = x + dx, y + dy\n",
        "            \n",
        "            # Проверяем границы и посещение\n",
        "            if not (half_patch <= nx < sw - half_patch and half_patch <= ny < sh - half_patch):\n",
        "                continue\n",
        "            if mask[ny, nx] != 0:\n",
        "                continue\n",
        "            \n",
        "            # БЫСТРАЯ проверка: сходство по цвету\n",
        "            current_color = small_color[ny, nx].astype(np.float32)\n",
        "            color_diff = np.linalg.norm(current_color - seed_color)\n",
        "            \n",
        "            if color_diff > color_threshold:\n",
        "                continue  # Слишком разные по цвету - пропускаем\n",
        "            \n",
        "            # МЕДЛЕННАЯ проверка: сходство по текстуре (только для похожих по цвету)\n",
        "            current_patch_lbp = lbp[ny - half_patch: ny + half_patch + 1,\n",
        "                                    nx - half_patch: nx + half_patch + 1]\n",
        "            current_lbp_hist, _ = np.histogram(current_patch_lbp, bins=n_points + 2,\n",
        "                                                range=(0, n_points + 2), density=True)\n",
        "            \n",
        "            # Сравниваем гистограммы с помощью корреляции\n",
        "            texture_score = cv2.compareHist(target_lbp_hist.astype(np.float32),\n",
        "                                            current_lbp_hist.astype(np.float32),\n",
        "                                            cv2.HISTCMP_CORREL)\n",
        "            \n",
        "            # Если текстура похожа, добавляем пиксель в регион\n",
        "            if texture_score > texture_threshold:\n",
        "                mask[ny, nx] = 255\n",
        "                queue.append((nx, ny))\n",
        "                processed_pixels += 1\n",
        "    \n",
        "    print(f\"Обработано пикселей: {processed_pixels}\")\n",
        "    \n",
        "    # Масштабируем маску обратно к исходному размеру\n",
        "    if scale_factor > 1:\n",
        "        mask = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "    \n",
        "    # Морфологическая обработка для сглаживания\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)  # Закрываем дыры\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)   # Убираем шум\n",
        "    \n",
        "    # Накладываем результат на исходное изображение\n",
        "    output_image = image.copy()\n",
        "    output_image[mask == 255] = [0, 255, 0]  # Зелёный цвет для выделенного региона\n",
        "    \n",
        "    return output_image, True\n",
        "\n",
        "print(\"✓ Все функции обработки определены\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Вспомогательные функции для визуализации\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_comparison(original, processed, title):\n",
        "    \"\"\"\n",
        "    Отображает исходное и обработанное изображения рядом.\n",
        "    \n",
        "    Параметры:\n",
        "        original: исходное изображение (BGR)\n",
        "        processed: обработанное изображение (BGR)\n",
        "        title: заголовок\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
        "    fig.suptitle(title, fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Исходное изображение\n",
        "    original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
        "    axes[0].imshow(original_rgb)\n",
        "    axes[0].set_title('Исходное изображение', fontsize=12)\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Обработанное изображение\n",
        "    processed_rgb = cv2.cvtColor(processed, cv2.COLOR_BGR2RGB)\n",
        "    axes[1].imshow(processed_rgb)\n",
        "    axes[1].set_title('Результат обработки', fontsize=12)\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"✓ Функции визуализации определены\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Загрузка тестовых изображений\n",
        "\n",
        "Для тестирования используются три различных изображения. Поместите ваши изображения в папку `test_images/` с именами `test1.jpg`, `test2.jpg`, `test3.jpg`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создаём папку для тестовых изображений, если её нет\n",
        "os.makedirs('test_images', exist_ok=True)\n",
        "\n",
        "# Загружаем тестовые изображения\n",
        "test_images = []\n",
        "image_paths = ['test_images/test1.jpg', 'test_images/test2.jpg', 'test_images/test3.jpg']\n",
        "\n",
        "for path in image_paths:\n",
        "    if os.path.exists(path):\n",
        "        img = cv2.imread(path)\n",
        "        if img is not None:\n",
        "            test_images.append(img)\n",
        "            print(f\"Загружено: {path}, размер: {img.shape}\")\n",
        "\n",
        "if len(test_images) == 0:\n",
        "    print(\"\\n⚠️ ТЕСТОВЫЕ ИЗОБРАЖЕНИЯ НЕ НАЙДЕНЫ!\")\n",
        "    print(\"Создайте папку 'test_images' и поместите в неё файлы test1.jpg, test2.jpg, test3.jpg\")\n",
        "    print(\"\\nДля демонстрации создадим синтетические изображения...\")\n",
        "    \n",
        "    # Изображение 1: Линии и геометрические фигуры\n",
        "    img1 = np.ones((400, 600, 3), dtype=np.uint8) * 255\n",
        "    cv2.rectangle(img1, (100, 100), (250, 250), (100, 100, 100), -1)\n",
        "    cv2.line(img1, (50, 50), (550, 100), (0, 0, 0), 3)\n",
        "    cv2.line(img1, (100, 300), (500, 350), (0, 0, 0), 3)\n",
        "    cv2.line(img1, (300, 50), (350, 380), (0, 0, 0), 3)\n",
        "    \n",
        "    # Изображение 2: Окружности\n",
        "    img2 = np.ones((400, 600, 3), dtype=np.uint8) * 255\n",
        "    cv2.circle(img2, (150, 150), 60, (50, 50, 50), -1)\n",
        "    cv2.circle(img2, (400, 200), 80, (50, 50, 50), -1)\n",
        "    cv2.circle(img2, (300, 320), 50, (50, 50, 50), -1)\n",
        "    \n",
        "    # Изображение 3: Текстуры для сегментации\n",
        "    img3 = np.ones((400, 600, 3), dtype=np.uint8) * 255\n",
        "    # Регион 1: Вертикальные линии\n",
        "    for i in range(0, 300, 5):\n",
        "        cv2.line(img3, (i, 0), (i, 200), (100, 150, 100), 2)\n",
        "    # Регион 2: Горизонтальные линии\n",
        "    for i in range(0, 200, 5):\n",
        "        cv2.line(img3, (300, i), (600, i), (150, 100, 150), 2)\n",
        "    # Регион 3: Крестообразные линии\n",
        "    for i in range(200, 400, 10):\n",
        "        cv2.line(img3, (0, i), (300, i), (100, 100, 150), 1)\n",
        "        cv2.line(img3, (0, i-5), (300, i-5), (100, 100, 150), 1)\n",
        "    for j in range(0, 300, 10):\n",
        "        cv2.line(img3, (j, 200), (j, 400), (100, 100, 150), 1)\n",
        "    \n",
        "    test_images = [img1, img2, img3]\n",
        "    print(\"✓ Созданы синтетические тестовые изображения\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Результаты обработки\n",
        "\n",
        "Ниже представлены результаты применения всех функций к каждому из трёх тестовых изображений.\n",
        "\n",
        "---\n",
        "\n",
        "### Изображение 1: Обнаружение линий\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(test_images) >= 1:\n",
        "    img = test_images[0]\n",
        "    result = find_hough_lines(img)\n",
        "    display_comparison(img, result, 'Изображение 1: Обнаружение линий методом Хафа')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Изображение 2: Обнаружение окружностей\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(test_images) >= 2:\n",
        "    img = test_images[1]\n",
        "    result = find_hough_circles(img)\n",
        "    display_comparison(img, result, 'Изображение 2: Обнаружение окружностей методом Хафа')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Изображение 3: Сегментация по текстуре\n",
        "\n",
        "Для демонстрации выбираем несколько затравочных точек в разных регионах изображения.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(test_images) >= 3:\n",
        "    img = test_images[2]\n",
        "    h, w = img.shape[:2]\n",
        "    \n",
        "    # Выбираем несколько затравочных точек для демонстрации\n",
        "    seed_points = [\n",
        "        (150, 100, \"Регион 1\"),  # Вертикальные линии\n",
        "        (450, 100, \"Регион 2\"),  # Горизонтальные линии\n",
        "        (150, 300, \"Регион 3\"),  # Крестообразные линии\n",
        "    ]\n",
        "    \n",
        "    for seed_x, seed_y, region_name in seed_points:\n",
        "        print(f\"\\n{region_name}: затравочная точка ({seed_x}, {seed_y})\")\n",
        "        result, success = segment_by_texture(img, seed_x, seed_y)\n",
        "        if success:\n",
        "            display_comparison(img, result, f'Изображение 3: Сегментация по текстуре - {region_name}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Дополнительное тестирование на всех изображениях\n",
        "\n",
        "Применим все методы к оставшимся изображениям для полноты тестирования.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Тестируем обнаружение окружностей на изображении 1\n",
        "if len(test_images) >= 1:\n",
        "    print(\"\\n=== Изображение 1: Обнаружение окружностей ===\")\n",
        "    img = test_images[0]\n",
        "    result = find_hough_circles(img)\n",
        "    display_comparison(img, result, 'Изображение 1: Обнаружение окружностей')\n",
        "\n",
        "# Тестируем обнаружение линий на изображении 2\n",
        "if len(test_images) >= 2:\n",
        "    print(\"\\n=== Изображение 2: Обнаружение линий ===\")\n",
        "    img = test_images[1]\n",
        "    result = find_hough_lines(img)\n",
        "    display_comparison(img, result, 'Изображение 2: Обнаружение линий')\n",
        "\n",
        "# Тестируем сегментацию на изображении 1\n",
        "if len(test_images) >= 1:\n",
        "    print(\"\\n=== Изображение 1: Сегментация ===\")\n",
        "    img = test_images[0]\n",
        "    h, w = img.shape[:2]\n",
        "    # Выбираем точку в центре прямоугольника\n",
        "    result, success = segment_by_texture(img, 175, 175)\n",
        "    if success:\n",
        "        display_comparison(img, result, 'Изображение 1: Сегментация по текстуре')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Выводы\n",
        "\n",
        "### Преобразование Хафа для прямых линий\n",
        "\n",
        "**Принцип работы:**\n",
        "- Преобразование Хафа переводит задачу обнаружения линий из пространства изображения в параметрическое пространство (ρ, θ)\n",
        "- Каждая точка на краях изображения может принадлежать множеству линий, образующих синусоиду в пространстве параметров\n",
        "- Точки пересечения синусоид соответствуют параметрам реальных линий на изображении\n",
        "\n",
        "**Результаты:**\n",
        "- Вероятностное преобразование Хафа (HoughLinesP) эффективно находит прямые линии на изображениях\n",
        "- Метод устойчив к разрывам в линиях благодаря параметру `maxLineGap`\n",
        "- Параметр `minLineLength` позволяет отфильтровать короткие шумовые сегменты\n",
        "- Предварительное применение детектора Canny критично для качества результатов\n",
        "\n",
        "**Ограничения:**\n",
        "- Требует тщательной настройки параметров для разных типов изображений\n",
        "- Может пропустить линии с малым контрастом\n",
        "- Не различает отдельные близко расположенные параллельные линии\n",
        "\n",
        "### Преобразование Хафа для окружностей\n",
        "\n",
        "**Принцип работы:**\n",
        "- Обобщение преобразования Хафа на трёхмерное пространство параметров (x, y, r)\n",
        "- Метод HOUGH_GRADIENT использует градиенты изображения для поиска центров окружностей\n",
        "- Аккумулятор накапливает \"голоса\" за возможные центры окружностей\n",
        "\n",
        "**Результаты:**\n",
        "- Метод успешно обнаруживает окружности различного размера\n",
        "- Предобработка (размытие + CLAHE) значительно улучшает качество обнаружения\n",
        "- CLAHE (адаптивная эквализация гистограммы) помогает выявить окружности при неравномерном освещении\n",
        "- Параметр `minDist` эффективно предотвращает множественное обнаружение одной окружности\n",
        "\n",
        "**Ограничения:**\n",
        "- Чувствителен к шуму и требует качественной предобработки\n",
        "- Параметр `param2` требует тонкой настройки: слишком малое значение даёт много ложных срабатываний\n",
        "- Не обнаруживает эллипсы и деформированные окружности\n",
        "- Вычислительно затратен для больших изображений\n",
        "\n",
        "### Сегментация по текстуре с использованием LBP\n",
        "\n",
        "**Принцип работы:**\n",
        "- Локальные бинарные паттерны (LBP) кодируют локальную текстуру вокруг каждого пикселя\n",
        "- Алгоритм роста регионов расширяет регион от затравочной точки, добавляя пиксели с похожей текстурой\n",
        "- Комбинированный критерий (цвет + текстура) обеспечивает более точную сегментацию\n",
        "\n",
        "**Результаты:**\n",
        "- LBP эффективно описывает текстурные паттерны, устойчив к изменениям освещённости\n",
        "- Двухэтапная фильтрация (быстрая по цвету, медленная по текстуре) значительно ускоряет алгоритм\n",
        "- Морфологические операции (closing/opening) сглаживают границы и устраняют шум\n",
        "- Масштабирование изображения позволяет обрабатывать большие изображения за разумное время\n",
        "\n",
        "**Ограничения:**\n",
        "- Качество зависит от выбора затравочной точки\n",
        "- Пороги (color_threshold, texture_threshold) требуют настройки для разных изображений\n",
        "- Не работает для регионов без выраженной текстуры\n",
        "- Вычислительно затратен для сложных текстур на больших изображениях\n",
        "\n",
        "### Общие наблюдения\n",
        "\n",
        "1. **Предобработка критична**: все методы требуют качественной предобработки (размытие, эквализация, детектор краёв)\n",
        "\n",
        "2. **Баланс точность/скорость**: уменьшение разрешения для сегментации даёт хорошее соотношение скорости и качества\n",
        "\n",
        "3. **Настройка параметров**: каждый метод имеет несколько критичных параметров, требующих настройки под конкретную задачу\n",
        "\n",
        "4. **Комбинирование методов**: использование нескольких признаков (цвет + текстура) даёт более робастные результаты\n",
        "\n",
        "5. **Практическое применение**:\n",
        "   - Преобразование Хафа: обнаружение объектов правильной формы в системах технического зрения\n",
        "   - Сегментация по текстуре: медицинская визуализация, анализ материалов, распознавание объектов\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (CV Labs)",
      "language": "python",
      "name": "cv-lab-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

"""
Deep Learning Models for Clock Time Recognition
Implements CNN-based architectures for accurate time detection
"""
import numpy as np
import cv2
from typing import Tuple, Optional, Dict
import os


class ClockTimeRecognitionModel:
    """
    Deep learning model for recognizing time from clock faces
    Uses a hybrid approach with CNN backbone and dual output heads
    """
    
    def __init__(self, model_path: Optional[str] = None):
        self.model_path = model_path
        self.model = None
        self.is_trained = False
        
        # Model architecture parameters
        self.input_size = (224, 224)
        self.num_hours = 12
        
    def preprocess_clock_face(self, clock_img: np.ndarray) -> np.ndarray:
        """
        Preprocess clock face for model input
        - Resize to standard size
        - Normalize pixel values
        - Apply spatial transformations
        """
        # Resize
        processed = cv2.resize(clock_img, self.input_size)
        
        # Convert to RGB if needed
        if len(processed.shape) == 2:
            processed = cv2.cvtColor(processed, cv2.COLOR_GRAY2RGB)
        elif processed.shape[2] == 4:
            processed = cv2.cvtColor(processed, cv2.COLOR_BGRA2RGB)
        
        # Normalize to [0, 1]
        processed = processed.astype(np.float32) / 255.0
        
        # Add batch dimension
        processed = np.expand_dims(processed, axis=0)
        
        return processed
    
    def predict_time(self, clock_face: np.ndarray) -> Tuple[int, int, float]:
        """
        Predict time from clock face image
        Returns: (hour, minute, confidence)
        """
        # For now, use classical CV approach as fallback
        # This will be replaced with actual neural network when trained
        return self._predict_with_classical_cv(clock_face)
    
    def _predict_with_classical_cv(self, clock_face: np.ndarray) -> Tuple[int, int, float]:
        """
        Classical computer vision approach for time detection
        COMPLETELY REWRITTEN with proper hand detection logic
        """
        # Get dimensions
        if len(clock_face.shape) == 3:
            color = clock_face.copy()
            gray = cv2.cvtColor(clock_face, cv2.COLOR_BGR2GRAY)
        else:
            gray = clock_face.copy()
            color = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
        
        height, width = gray.shape
        center_x, center_y = width // 2, height // 2
        radius = min(width, height) // 2 - 10
        
        # Try color-based detection first (for colored hands)
        hsv = cv2.cvtColor(color, cv2.COLOR_BGR2HSV)
        
        # Create mask for potential hand colors (yellow/gold, black, white, red)
        # Yellow/Gold
        lower_yellow = np.array([15, 50, 50])
        upper_yellow = np.array([35, 255, 255])
        mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)
        
        # Black/Dark (low value)
        lower_black = np.array([0, 0, 0])
        upper_black = np.array([180, 255, 50])
        mask_black = cv2.inRange(hsv, lower_black, upper_black)
        
        # White/Light (high value)
        lower_white = np.array([0, 0, 200])
        upper_white = np.array([180, 30, 255])
        mask_white = cv2.inRange(hsv, lower_white, upper_white)
        
        # Combine masks
        hand_mask = cv2.bitwise_or(mask_yellow, mask_black)
        hand_mask = cv2.bitwise_or(hand_mask, mask_white)
        
        # Create circular mask for clock region
        circle_mask = np.zeros_like(gray)
        cv2.circle(circle_mask, (center_x, center_y), int(radius * 0.95), 255, -1)
        
        # Apply circular mask
        hand_mask = cv2.bitwise_and(hand_mask, hand_mask, mask=circle_mask)
        
        # Morphological operations
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        hand_mask = cv2.morphologyEx(hand_mask, cv2.MORPH_CLOSE, kernel)
        hand_mask = cv2.morphologyEx(hand_mask, cv2.MORPH_OPEN, kernel)
        
        # Find contours
        contours, _ = cv2.findContours(hand_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        hand_candidates = []
        
        # Analyze contours
        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 50:  # Too small
                continue
            
            # Fit line to contour
            if len(contour) < 5:
                continue
            
            [vx, vy, x0, y0] = cv2.fitLine(contour, cv2.DIST_L2, 0, 0.01, 0.01)
            
            # Calculate line endpoints through center
            line_length = radius * 1.5
            x1 = int(x0 - vx * line_length)
            y1 = int(y0 - vy * line_length)
            x2 = int(x0 + vx * line_length)
            y2 = int(y0 + vy * line_length)
            
            # Check distances to center
            d1 = np.hypot(x1 - center_x, y1 - center_y)
            d2 = np.hypot(x2 - center_x, y2 - center_y)
            
            # Distance from contour center to clock center
            M = cv2.moments(contour)
            if M["m00"] != 0:
                cx_cont = int(M["m10"] / M["m00"])
                cy_cont = int(M["m01"] / M["m00"])
                dist_to_center = np.hypot(cx_cont - center_x, cy_cont - center_y)
                
                # Find the far end (tip)
                if d1 > d2:
                    tip_x, tip_y = x1, y1
                    tip_dist = d1
                else:
                    tip_x, tip_y = x2, y2
                    tip_dist = d2
                
                # Calculate angle
                angle = self._calculate_angle(tip_x, tip_y, center_x, center_y)
                
                # Get bounding rect for length estimate
                rect = cv2.minAreaRect(contour)
                length = max(rect[1])
                
                hand_candidates.append({
                    'angle': angle,
                    'length': length,
                    'area': area,
                    'tip_dist': tip_dist,
                    'center_dist': dist_to_center,
                    'contour': contour
                })
        
        # Fallback to edge detection if color detection failed
        if len(hand_candidates) < 2:
            blurred = cv2.GaussianBlur(gray, (7, 7), 1.5)
            edges = cv2.Canny(blurred, 30, 90)
            edges = cv2.bitwise_and(edges, edges, mask=circle_mask)
            
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, 40, minLineLength=int(radius*0.3), maxLineGap=int(radius*0.2))
            
            if lines is not None:
                for line in lines:
                    x1, y1, x2, y2 = line[0]
                    d1 = np.hypot(x1 - center_x, y1 - center_y)
                    d2 = np.hypot(x2 - center_x, y2 - center_y)
                    
                    if min(d1, d2) < radius * 0.25 and max(d1, d2) > radius * 0.4:
                        tip_x, tip_y = (x1, y1) if d1 > d2 else (x2, y2)
                        angle = self._calculate_angle(tip_x, tip_y, center_x, center_y)
                        length = np.hypot(x2 - x1, y2 - y1)
                        
                        hand_candidates.append({
                            'angle': angle,
                            'length': length,
                            'area': length * 5,
                            'tip_dist': max(d1, d2),
                            'center_dist': min(d1, d2),
                            'contour': None
                        })
        
        if len(hand_candidates) < 2:
            return 0, 0, 0.0
        
        # Remove duplicate angles
        hand_candidates.sort(key=lambda x: x['tip_dist'], reverse=True)
        unique = []
        for cand in hand_candidates:
            is_dup = False
            for existing in unique:
                diff = abs(cand['angle'] - existing['angle'])
                diff = min(diff, 360 - diff)
                if diff < 12:
                    if cand['tip_dist'] > existing['tip_dist']:
                        unique.remove(existing)
                        unique.append(cand)
                    is_dup = True
                    break
            if not is_dup:
                unique.append(cand)
        
        if len(unique) < 2:
            return 0, 0, 0.0
        
        # Sort by tip distance - longer hand is minute
        unique.sort(key=lambda x: x['tip_dist'], reverse=True)
        
        minute_hand = unique[0]
        hour_hand = unique[1]
        
        # Get angles
        minute_angle = minute_hand['angle']
        hour_angle = hour_hand['angle']
        
        # Convert to time
        minute = int(round(minute_angle / 6.0)) % 60
        
        # Hour calculation with minute adjustment
        hour_from_angle = (hour_angle - minute * 0.5) / 30.0
        hour = int(round(hour_from_angle)) % 12
        
        # Validate
        expected_hour_angle = (hour * 30 + minute * 0.5) % 360
        error = self._angle_diff(expected_hour_angle, hour_angle)
        
        if error > 25:
            for test_h in [(hour - 1) % 12, (hour + 1) % 12]:
                test_angle = (test_h * 30 + minute * 0.5) % 360
                test_error = self._angle_diff(test_angle, hour_angle)
                if test_error < error:
                    error = test_error
                    hour = test_h
        
        confidence = max(0.5, 1.0 - error / 60.0)
        
        return hour, minute, confidence
    
    def _calculate_angle(self, x: float, y: float, cx: float, cy: float) -> float:
        """Calculate angle from center, 0Â° at 12 o'clock, clockwise"""
        dx = x - cx
        dy = cy - y  # Invert y for standard math orientation
        angle = np.degrees(np.arctan2(dy, dx))
        angle = (90 - angle) % 360  # Convert to clock orientation
        return angle
    
    def _angle_diff(self, angle1: float, angle2: float) -> float:
        """Calculate minimum difference between two angles"""
        diff = abs(angle1 - angle2)
        return min(diff, 360 - diff)
    
    def load_model(self, model_path: str) -> bool:
        """Load pre-trained model"""
        if not os.path.exists(model_path):
            print(f"Model file not found: {model_path}")
            return False
        
        try:
            # This would load actual neural network weights
            # For now, mark as not using neural network
            self.is_trained = False
            return False
        except Exception as e:
            print(f"Error loading model: {e}")
            return False


class ClockDetectionModel:
    """
    Model for detecting and localizing clock faces in images
    Uses circle detection and deep learning approaches
    """
    
    def __init__(self):
        self.detection_method = "hough_circles"
        
    def detect_clock_face(self, image: np.ndarray) -> Optional[Dict]:
        """
        Detect clock face in image
        Returns: dict with bbox, center, radius or None
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # Enhanced preprocessing
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # Try multiple parameter sets for Hough Circles
        param_sets = [
            {'dp': 1.2, 'minDist': 100, 'param1': 120, 'param2': 40},
            {'dp': 1.0, 'minDist': 100, 'param1': 100, 'param2': 35},
            {'dp': 1.5, 'minDist': 80, 'param1': 150, 'param2': 45},
        ]
        
        all_circles = []
        for params in param_sets:
            circles = cv2.HoughCircles(
                blurred,
                cv2.HOUGH_GRADIENT,
                dp=params['dp'],
                minDist=params['minDist'],
                param1=params['param1'],
                param2=params['param2'],
                minRadius=30,
                maxRadius=min(gray.shape) // 2
            )
            
            if circles is not None:
                all_circles.extend(circles[0])
        
        if not all_circles:
            return None
        
        # Find the best circle (largest, most centered)
        best_circle = self._select_best_circle(all_circles, gray.shape)
        
        if best_circle is None:
            return None
        
        cx, cy, r = best_circle
        
        return {
            'center': (int(cx), int(cy)),
            'radius': int(r),
            'bbox': (int(cx - r), int(cy - r), int(2 * r), int(2 * r))
        }
    
    def _select_best_circle(self, circles: list, image_shape: tuple) -> Optional[Tuple[float, float, float]]:
        """Select the most likely clock circle"""
        if not circles:
            return None
        
        height, width = image_shape
        img_center_x, img_center_y = width / 2, height / 2
        
        # Score circles based on size and centrality
        scored_circles = []
        for circle in circles:
            if len(circle) < 3:
                continue
                
            cx, cy, r = circle[0], circle[1], circle[2]
            
            # Distance from image center (normalized)
            dist_from_center = np.hypot(cx - img_center_x, cy - img_center_y)
            max_dist = np.hypot(width, height) / 2
            centrality_score = 1 - (dist_from_center / max_dist)
            
            # Size score (prefer larger circles)
            size_score = r / (min(width, height) / 2)
            
            # Combined score
            score = 0.6 * size_score + 0.4 * centrality_score
            
            scored_circles.append((score, (cx, cy, r)))
        
        if not scored_circles:
            return None
        
        # Return circle with highest score
        scored_circles.sort(key=lambda x: x[0], reverse=True)
        return scored_circles[0][1]
    
    def extract_clock_face(self, image: np.ndarray, detection: Dict) -> np.ndarray:
        """Extract and crop clock face from image"""
        x, y, w, h = detection['bbox']
        
        # Add some padding
        padding = int(w * 0.1)
        x = max(0, x - padding)
        y = max(0, y - padding)
        w = min(image.shape[1] - x, w + 2 * padding)
        h = min(image.shape[0] - y, h + 2 * padding)
        
        cropped = image[y:y+h, x:x+w]
        
        return cropped


def create_preprocessing_pipeline(image: np.ndarray) -> np.ndarray:
    """
    Standard preprocessing pipeline for clock images
    """
    # Ensure RGB format
    if len(image.shape) == 2:
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
    
    # Denoise
    denoised = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)
    
    # Enhance contrast
    lab = cv2.cvtColor(denoised, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    enhanced = cv2.merge([l, a, b])
    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
    
    return enhanced

